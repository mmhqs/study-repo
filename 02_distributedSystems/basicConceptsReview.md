# üîç SE√á√ÉO I: REVIS√ÉO DE PR√â-REQUISITOS
## Quest√£o 1 - Sistemas operacionais
### a) Explique a diferen√ßa entre processo e thread, destacando as implica√ß√µes para sistemas distribu√≠dos.

Um **processo** √© uma inst√¢ncia de um programa em execu√ß√£o. Ele √© uma entidade aut√¥noma e independente que possui seu pr√≥prio espa√ßo de endere√ßamento de mem√≥ria, c√≥digo, dados e recursos do sistema operacional. Em um sistema distribu√≠do, os processos s√£o a base para a distribui√ß√£o de tarefas entre diferentes n√≥s (m√°quinas). Cada n√≥ da rede pode executar um ou mais processos independentes. A comunica√ß√£o entre processos em m√°quinas distintas √© tipicamente mais complexa e lenta, usando mecanismos como RPC (Remote Procedure Call) ou passagem de mensagens.

Uma **thread**, ou linha de execu√ß√£o, √© uma unidade de execu√ß√£o que reside dentro de um processo. M√∫ltiplas threads de um mesmo processo compartilham o mesmo espa√ßo de mem√≥ria, al√©m de outros recursos. Por serem mais leves, a cria√ß√£o e a troca de contexto entre threads s√£o mais r√°pidas do que entre processos. A principal implica√ß√£o de threads para sistemas distribu√≠dos √© a capacidade de paralelizar tarefas dentro de um √∫nico n√≥. Por exemplo, um servidor em uma arquitetura cliente-servidor pode usar threads para atender a m√∫ltiplas requisi√ß√µes de clientes ao mesmo tempo. Isso melhora o desempenho e a responsividade sem a necessidade de criar um novo processo para cada requisi√ß√£o.

| Caracter√≠stica       | Processo                          | Thread                                    |
|-----------------------|-----------------------------------|-------------------------------------------|
| Independ√™ncia         | Independente e isolado            | Dependente do processo principal          |
| Mem√≥ria               | Espa√ßo de mem√≥ria pr√≥prio         | Compartilha mem√≥ria do processo           |
| Custo                 | Cria√ß√£o e troca de contexto lentas| Cria√ß√£o e troca de contexto r√°pidas       |
| Comunica√ß√£o           | Via IPC (lenta)                   | Via mem√≥ria compartilhada (r√°pida)        |
| Toler√¢ncia a Falhas   | Uma falha n√£o afeta outros processos | Uma falha pode derrubar o processo e suas outras threads |

### b) Descreva os cinco estados de um processo (novo, pronto, executando, esperando, terminado) e explique como esses estados se relacionam com processos distribu√≠dos executando em diferentes m√°quinas.

Esses cinco estados s√£o o ciclo de vida de um processo em execu√ß√£o. Abaixo apresento os cinco estados e suas descri√ß√µes.
1. `Novo`: o processo est√° sendo criado. Ele ainda n√£o est√° carregado na mem√≥ria principal, mas j√° tem um Bloco de Controle de Processo (BCP) associado a ele.
2. `Pronto`: o processo est√° pronto para ser executado e est√° aguardando na fila de processos do escalonador do sistema operacional. Ele est√° na mem√≥ria principal e espera apenas o CPU ficar dispon√≠vel.
3. `Executando`: o processo est√° atualmente utilizando o CPU e suas instru√ß√µes est√£o sendo executadas. Em um sistema com um √∫nico CPU, apenas um processo pode estar neste estado por vez.
4. `Esperando`: o processo foi temporariamente suspenso. Isso acontece quando ele precisa aguardar a conclus√£o de algum evento, como uma opera√ß√£o de entrada/sa√≠da (I/O) ou a libera√ß√£o de um recurso.
5. `Terminado`: o processo concluiu sua execu√ß√£o. O sistema operacional est√° liberando todos os seus recursos e o processo √© removido da mem√≥ria.

Em um sistema distribu√≠do, o gerenciamento desses estados se torna mais complexo, pois eles ocorrem em m√∫ltiplas m√°quinas que se comunicam atrav√©s de uma rede.

- Estados locais: os estados `Pronto` e `Executando` s√£o sempre locais a um n√≥ (m√°quina) espec√≠fico. Um processo s√≥ pode estar "executando" no CPU de um computador por vez. A gest√£o da fila de processos "prontos" tamb√©m √© feita localmente por cada sistema operacional.
- Comunica√ß√£o entre m√°quinas: o estado de `Esperando` √© afetado. Em um sistema distribu√≠do, um processo pode entrar no estado de espera n√£o apenas por uma opera√ß√£o de I/O local, mas tamb√©m por eventos remotos. Por exemplo, um processo em um servidor pode estar esperando uma resposta de um cliente em outra m√°quina ou a conclus√£o de uma tarefa em um banco de dados remoto. A lat√™ncia da rede pode prolongar significativamente o tempo de espera.
- Gerenciamento distribu√≠do: os estados `Novo` e `Terminado` podem ser iniciados remotamente. Um processo em uma m√°quina pode solicitar a cria√ß√£o de um novo processo em outra m√°quina para realizar uma tarefa. Da mesma forma, a termina√ß√£o de um processo pode ser coordenada remotamente. Algoritmos de balanceamento de carga em sistemas distribu√≠dos buscam otimizar os estados `Pronto` e `Executando`, movendo processos entre n√≥s para evitar que um √∫nico computador fique sobrecarregado.

A principal implica√ß√£o √© que, embora os estados de um processo sejam os mesmos, as transi√ß√µes entre eles em um ambiente distribu√≠do s√£o influenciadas pela rede, pela dist√¢ncia e pela comunica√ß√£o entre os n√≥s, o que introduz desafios como falhas de conex√£o e sincroniza√ß√£o.

### c) Compare tr√™s mecanismos de IPC (Inter-Process Communication): pipes, sockets e mem√≥ria compartilhada. Como estes conceitos se estendem para comunica√ß√£o em sistemas distribu√≠dos?

| Caracter√≠stica            | Pipes                                 | Mem√≥ria Compartilhada                        | Sockets                                |
|----------------------------|---------------------------------------|----------------------------------------------|----------------------------------------|
| **Escopo**                 | Local (mesma m√°quina)                | Local (mesma m√°quina)                        | Local ou Remoto (via rede)             |
| **Velocidade**             | R√°pida (para comunica√ß√£o sequencial) | Muito R√°pida (mais r√°pida de todas)          | Lenta (depende da lat√™ncia da rede)    |
| **Complexidade**           | Simples                              | Alta (exige gerenciamento de sincroniza√ß√£o)  | M√©dia (programa√ß√£o de rede)            |
| **Aplica√ß√µes Distribu√≠das**| N√£o aplic√°vel                        | Conceito estendido via DSM                   | Fundamental e principal mecanismo       |

**Pipes**
- Como funcionam: s√£o canais de comunica√ß√£o unidirecionais (de m√£o √∫nica) que permitem a transfer√™ncia de dados entre dois processos. Existem pipes an√¥nimos (geralmente entre processos pai e filho) e pipes nomeados, que podem ser usados por processos n√£o relacionados na mesma m√°quina.
- Implica√ß√µes em sistemas distribu√≠dos: o mecanismo totalmente local! N√£o podem ser usados para comunica√ß√£o entre m√°quinas diferentes em uma rede! S√£o √∫teis apenas para orquestrar processos dentro de um √∫nico computador.

**Mem√≥ria compartilhada**
- Como funciona: v√°rios processos acessam a mesma regi√£o da mem√≥ria principal. √â o m√©todo mais r√°pido de IPC porque evita a c√≥pia de dados entre o espa√ßo de mem√≥ria do kernel e o espa√ßo de mem√≥ria dos processos. No entanto, exige um alto n√≠vel de sincroniza√ß√£o para evitar condi√ß√µes de corrida, onde m√∫ltiplos processos tentam escrever na mesma √°rea ao mesmo tempo.
- Implica√ß√µes em sistemas distribu√≠dos: o conceito, por si s√≥, n√£o se aplica a um ambiente distribu√≠do, j√° que os processos est√£o em m√°quinas fisicamente separadas com mem√≥rias distintas! A ideia √© estendida por meio da Mem√≥ria Compartilhada Distribu√≠da (DSM), um sistema de software complexo que cria a ilus√£o de um espa√ßo de mem√≥ria compartilhado entre os n√≥s de uma rede. No entanto, a implementa√ß√£o √© desafiadora, e a lat√™ncia da rede e a consist√™ncia dos dados se tornam problemas cr√≠ticos.

**Sockets**
- Como funcionam: um socket √© um ponto final de comunica√ß√£o que pode ser usado para trocar dados com outro socket. Ao contr√°rio dos pipes e da mem√≥ria compartilhada, os sockets foram projetados desde o in√≠cio para a comunica√ß√£o em rede! Eles podem ser configurados para se comunicar com outro socket na mesma m√°quina ou em qualquer m√°quina acess√≠vel pela rede.
- Implica√ß√µes em sistemas distribu√≠dos: os sockets s√£o a base de comunica√ß√£o dos sistemas distribu√≠dos! Eles formam a camada fundamental sobre a qual protocolos de rede mais avan√ßados, como TCP e UDP, s√£o constru√≠dos. Mecanismos de comunica√ß√£o de alto n√≠vel, como as Chamadas de Procedimento Remoto (RPC), usam sockets para permitir que um processo em uma m√°quina invoque uma fun√ß√£o em um processo em outra m√°quina, fazendo com que a comunica√ß√£o remota se pare√ßa com uma chamada de fun√ß√£o local.


### d) Explique os algoritmos de substitui√ß√£o de p√°gina FIFO, LRU e Optimal. Como o gerenciamento de mem√≥ria virtual se relaciona com sistemas de mem√≥ria distribu√≠da?

Os algoritmos de substitui√ß√£o de p√°gina s√£o estrat√©gias usadas por sistemas de mem√≥ria virtual para decidir qual p√°gina remover da mem√≥ria principal quando uma nova p√°gina precisa ser carregada.
- FIFO (First-In, First-Out): este √© o algoritmo mais simples. Ele remove a p√°gina que est√° na mem√≥ria h√° mais tempo, ou seja, a "primeira a entrar" √© a "primeira a sair". A principal desvantagem √© que ele n√£o leva em conta a frequ√™ncia de uso da p√°gina. Uma p√°gina muito utilizada pode ser removida apenas por ser a mais antiga, levando a um aumento desnecess√°rio de falhas de p√°gina.
- LRU (Least Recently Used): o LRU remove a p√°gina que n√£o foi usada pelo maior tempo. A ideia √© que a p√°gina que n√£o foi acessada por mais tempo √© a que tem menor probabilidade de ser necess√°ria no futuro pr√≥ximo. Embora seja mais eficiente que o FIFO, o LRU exige um controle extra para monitorar o tempo de uso de cada p√°gina, o que pode aumentar a sobrecarga do sistema.
- Optimal: este algoritmo √© considerado o ideal, mas √© impratic√°vel de ser implementado. Ele remove a p√°gina que n√£o ser√° usada pelo maior per√≠odo de tempo no futuro. Para isso, o algoritmo precisaria ter conhecimento pr√©vio de toda a sequ√™ncia de acessos futuros, o que √© imposs√≠vel em um sistema real. O Optimal serve como uma refer√™ncia te√≥rica para avaliar o desempenho de outros algoritmos.

A mem√≥ria virtual cria a ilus√£o de um espa√ßo de mem√≥ria grande e cont√≠guo em um √∫nico computador, usando a hierarquia de mem√≥ria (RAM e disco).

O conceito de Mem√≥ria Compartilhada Distribu√≠da (DSM) √© a extens√£o desse princ√≠pio para um ambiente distribu√≠do. Ele cria a ilus√£o de um espa√ßo de mem√≥ria √∫nico e compartilhado em um sistema composto por v√°rias m√°quinas, cada uma com sua pr√≥pria mem√≥ria f√≠sica. Os algoritmos de substitui√ß√£o de p√°gina s√£o cruciais para a DSM, mas enfrentam novos desafios:
- Consist√™ncia dos dados: quando uma p√°gina √© replicada em v√°rias m√°quinas e uma delas a modifica, a DSM precisa garantir que as outras c√≥pias sejam atualizadas. A escolha do algoritmo de substitui√ß√£o afeta a frequ√™ncia de falhas e, consequentemente, a lat√™ncia para manter a consist√™ncia.
- Lat√™ncia da rede: em um sistema de mem√≥ria virtual tradicional, a falha de p√°gina envolve acesso ao disco r√≠gido. Em um sistema distribu√≠do, essa falha requer uma comunica√ß√£o pela rede para buscar a p√°gina em outro n√≥, o que √© muito mais lento. Um algoritmo ineficiente como o FIFO pode aumentar drasticamente as falhas de p√°gina distribu√≠das, degradando o desempenho do sistema.
- Decis√£o global: a decis√£o de qual p√°gina remover pode n√£o ser mais local. Pode ser necess√°rio um algoritmo de substitui√ß√£o que leve em conta a utiliza√ß√£o da p√°gina em todos os n√≥s, e n√£o apenas no n√≥ local, para otimizar o uso da mem√≥ria em todo o sistema.

Em resumo, o gerenciamento de mem√≥ria virtual em sistemas distribu√≠dos se torna muito mais complexo e a escolha do algoritmo de substitui√ß√£o de p√°gina √© ainda mais cr√≠tica, pois o custo de uma falha de p√°gina √© significativamente maior devido √† lat√™ncia da rede e √† necessidade de manter a consist√™ncia dos dados.

## Quest√£o 2 - Redes de Computadores
### a) Compare o modelo OSI (7 camadas) com o modelo TCP/IP (4 camadas). Quais camadas s√£o mais relevantes para desenvolvimento de sistemas distribu√≠dos e por qu√™?

O modelo OSI √© um padr√£o conceitual, mais completo e detalhado. Ele divide a comunica√ß√£o em 7 camadas distintas (F√≠sica, Enlace, Rede, Transporte, Sess√£o, Apresenta√ß√£o e Aplica√ß√£o). Ele √© usado principalmente para fins did√°ticos e para entender a estrutura geral das redes.  J√° o modelo TCP/IP √© um padr√£o pr√°tico, baseado nos protocolos que realmente impulsionam a internet. Ele simplifica a arquitetura para 4 camadas (Acesso √† Rede, Internet, Transporte e Aplica√ß√£o).

Para o desenvolvimento de sistemas distribu√≠dos, as camadas mais relevantes s√£o a de Transporte e a de Aplica√ß√£o.

- Camada de Transporte: esta camada √© crucial porque √© nela que voc√™ decide como os processos em diferentes m√°quinas ir√£o se comunicar. A escolha entre os protocolos TCP e UDP √© uma das decis√µes mais importantes.
- Camada de Aplica√ß√£o: esta √© a camada mais pr√≥xima do desenvolvedor. Ela define os protocolos e a l√≥gica de comunica√ß√£o de alto n√≠vel para sua aplica√ß√£o. √â aqui que voc√™ trabalha com APIs, como APIs REST (que usam HTTP, um protocolo da camada de aplica√ß√£o), gRPC ou web sockets. A forma como os processos da aplica√ß√£o interagem uns com os outros √© completamente definida nesta camada.

A camada de Transporte lida com a conex√£o entre os processos, enquanto a camada de Aplica√ß√£o lida com a linguagem que eles usam para se comunicar. Juntas, elas formam a base para construir sistemas que se estendem por v√°rias m√°quinas.

### b) Analise as diferen√ßas entre TCP e UDP em termos de confiabilidade, performance e adequa√ß√£o para diferentes tipos de aplica√ß√µes distribu√≠das. Forne√ßa exemplos pr√°ticos.

| Caracter√≠stica      | TCP                                           | UDP                                         |
|---------------------|-----------------------------------------------|---------------------------------------------|
| Confiabilidade      | Confi√°vel (com confirma√ß√£o e retransmiss√£o)   | N√£o confi√°vel (sem garantias)               |
| Overhead            | Alto (devido a mecanismos de controle)        | Baixo (m√≠nimo, apenas cabe√ßalho)            |
| Velocidade          | Mais lento (maior lat√™ncia)                   | Mais r√°pido (baixa lat√™ncia)                |
| Aplica√ß√µes T√≠picas  | Transfer√™ncia de arquivos, web, e-mail        | Streaming de v√≠deo/√°udio, jogos online, VoIP|

**TCP (Transmission Control Protocol)**
√â um protocolo orientado √† conex√£o, o que significa que ele estabelece uma conex√£o confi√°vel entre o remetente e o destinat√°rio antes de iniciar a transfer√™ncia de dados.
- `Confiabilidade`: √© a principal caracter√≠stica do TCP. Ele garante que os dados cheguem na ordem correta, sem perdas ou duplica√ß√µes. Isso √© feito por do three-way handshake, numera√ß√£o de pacotes e retransmiss√£o autom√°tica de pacotes perdidos ou danificados.
- `Performance`: devido a todos os mecanismos de garantia de entrega, o TCP tem um overhead maior. A necessidade de confirma√ß√µes e retransmiss√µes adiciona lat√™ncia, tornando-o mais lento que o UDP.
- `Adequa√ß√£o`: √© ideal para aplica√ß√µes onde a integridade dos dados √© crucial e a lat√™ncia secund√°ria.

Exemplos pr√°ticos:
- `Navega√ß√£o na Web` (HTTP/S): √© inaceit√°vel que partes de uma p√°gina web fiquem faltando ou cheguem fora de ordem. O TCP garante que voc√™ veja o site exatamente como ele foi enviado.
- `Transfer√™ncia de Arquivos` (FTP): o download de um arquivo de software, por exemplo, exige que cada byte seja transferido corretamente, sem erros.
- `E-mail` (SMTP): a mensagem precisa ser entregue na √≠ntegra para ser leg√≠vel e √∫til.

**UDP (User Datagram Protocol)**
√â um protocolo sem conex√£o. Ele opera de forma mais simples e direta, enviando pacotes de dados (chamados datagramas) sem qualquer garantia de entrega ou ordem. Pense nele como o servi√ßo postal: voc√™ envia uma carta e espera que chegue, mas n√£o h√° confirma√ß√£o ou garantia.
- `Confiabilidade`: o UDP √© n√£o confi√°vel. Ele n√£o possui mecanismos de confirma√ß√£o, retransmiss√£o ou controle de fluxo. Os pacotes podem chegar fora de ordem, duplicados ou, simplesmente, n√£o chegarem.
- `Performance`: como n√£o h√° overhead de handshake ou retransmiss√£o, o UDP √© extremamente r√°pido e leve. √â perfeito para aplica√ß√µes que exigem baixa lat√™ncia.
- `Adequa√ß√£o`: √© a escolha certa para aplica√ß√µes onde a velocidade √© mais importante que a confiabilidade perfeita, e onde a perda de alguns pacotes √© aceit√°vel.

Exemplos pr√°ticos:
- Streaming de v√≠deo e √°udio: em uma videochamada ou ao assistir a um filme, a perda de alguns milissegundos de √°udio ou um quadro de v√≠deo √© impercept√≠vel para o usu√°rio, mas a lat√™ncia causada pela espera de um pacote perdido seria muito not√°vel.
- Jogos online: a lat√™ncia (ou "ping") √© um fator cr√≠tico. √â prefer√≠vel perder um pacote de dados de movimento do que esperar por uma retransmiss√£o que causaria atraso e faria a partida parecer "lenta".
- Sistema de nomes de dom√≠nio (DNS): as requisi√ß√µes DNS s√£o pequenas e a velocidade √© essencial. Se uma resposta for perdida, √© mais r√°pido enviar a requisi√ß√£o novamente do que usar um protocolo complexo.

### c) Explique os conceitos de lat√™ncia, largura de banda e throughput. Como esses fatores impactam o design de arquiteturas distribu√≠das?

| Conceito        | Medida       | Impacto no design |
|-----------------|--------------|-------------------------------------------|
| Lat√™ncia        | Tempo (ms)   | Causa atrasos na comunica√ß√£o. Requer comunica√ß√£o ass√≠ncrona e caches para mitigar. |
| Largura de Banda| Volume (bps) | Limita a quantidade de dados. Requer compress√£o e otimiza√ß√µes de replica√ß√£o.       |
| Throughput      | Volume (bps) | √â a performance real. Requer balanceamento de carga e paralelismo para maximiza√ß√£o. |


- `Lat√™ncia`: √© o tempo que um √∫nico pacote de dados leva para viajar do ponto A ao ponto B. Pense nela como o atraso ou o tempo de resposta. A lat√™ncia √© geralmente medida em milissegundos (ms) e √© influenciada pela dist√¢ncia f√≠sica, pelos roteadores e pela sobrecarga da rede. A a alta lat√™ncia √© um dos maiores inimigos da performance em sistemas distribu√≠dos. Se um processo em um servidor precisa de dados de outro servidor para continuar, a alta lat√™ncia o obriga a esperar. Isso √© particularmente problem√°tico em algoritmos de consenso, onde todos os n√≥s precisam concordar sobre uma decis√£o. Para mitigar isso, os designers de sistemas usam:
1. Comunica√ß√£o ass√≠ncrona: em vez de esperar uma resposta, um processo envia uma solicita√ß√£o e continua seu trabalho, lidando com a resposta quando ela chega.
2. Cach√™s: manter uma c√≥pia de dados utilizados com frequ√™ncia perto do processo que os acessa reduz a necessidade de comunica√ß√£o remota.

- `Largura de banda`: √© a capacidade m√°xima de um canal de comunica√ß√£o, ou seja, a quantidade de dados que pode ser transmitida por segundo. √â a "estrada" da sua rede. A largura de banda √© medida em bits por segundo (bps). Em sistemas com baixa largura de banda, transferir grandes arquivos ou replicar bancos de dados inteiros se torna impratic√°vel. A solu√ß√£o √© otimizar o uso da banda com:
1. Compress√£o de dados: reduz o tamanho da informa√ß√£o antes de envi√°-la pela rede.
2. Replica√ß√£o seletiva: em vez de replicar todos os dados, replicar apenas o que √© essencial para o funcionamento de um n√≥, reduzindo a carga de rede.

- `Throughput` (Taxa de transfer√™ncia): √© a quantidade real de dados que um sistema transfere em um determinado per√≠odo. Ao contr√°rio da largura de banda (a capacidade m√°xima), o throughput √© o desempenho efetivo, que pode ser menor devido a fatores como lat√™ncia, perdas de pacotes ou lentid√£o no processamento. Se um sistema tem alta largura de banda e baixa lat√™ncia, mas ainda assim o throughput √© baixo, isso indica um gargalo em outro lugar (por exemplo, no processamento dos servidores ou no I/O do disco). Um bom design de sistema distribu√≠do busca maximizar o throughput atrav√©s de:
1. Paralelismo: dividir grandes tarefas em subtarefas menores que podem ser executadas em paralelo em diferentes n√≥s.
2. Balanceamento de carga: Distribuir as requisi√ß√µes uniformemente entre os servidores para que nenhum n√≥ seja sobrecarregado, mantendo a performance de todo o sistema.

### d) Discuta a import√¢ncia das APIs de rede (sockets) e do modelo cliente-servidor b√°sico como fundamento para comunica√ß√£o distribu√≠da.

O modelo cliente-servidor √© a base conceitual. Ele estabelece uma divis√£o clara e simples de pap√©is: um processo atua como servidor, oferecendo um servi√ßo, enquanto outro atua como cliente, solicitando e consumindo esse servi√ßo. Essa arquitetura √© crucial porque:

- Simplifica a l√≥gica: a intera√ß√£o se torna previs√≠vel. O cliente sempre inicia a comunica√ß√£o, e o servidor responde.
- Centraliza o controle: permite o gerenciamento de recursos, a seguran√ßa e a consist√™ncia dos dados em um √∫nico local, o servidor.

As APIs de rede, sendo os sockets o exemplo mais comum e fundamental, s√£o a implementa√ß√£o pr√°tica desse modelo. Um socket √© a interface de programa√ß√£o que permite que uma aplica√ß√£o se comunique atrav√©s da rede. Ele funciona como a "tomada de rede" de um programa, habilitando a troca de dados com outros programas, tanto na mesma m√°quina quanto em outra.

Em suma, o modelo cliente-servidor oferece a estrutura e a arquitetura para a comunica√ß√£o, enquanto os sockets fornecem a ferramenta de baixo n√≠vel necess√°ria para que essa comunica√ß√£o realmente aconte√ßa entre as m√°quinas. Juntos, eles formam o alicerce sobre o qual praticamente todos os sistemas distribu√≠dos, como a web e o e-mail, s√£o constru√≠dos.

# üåê SE√á√ÉO II: FUNDAMENTOS DE SISTEMAS DISTRIBU√çDOS
## Quest√£o 3 - Defini√ß√µes e Caracter√≠sticas
### a) Forne√ßa uma defini√ß√£o precisa de sistema distribu√≠do segundo Coulouris et al. Quais s√£o as tr√™s caracter√≠sticas que distinguem um sistema distribu√≠do de um sistema centralizado?
Segundo o livro "Sistemas Distribu√≠dos - Conceito e projeto" (4¬™ edi√ß√£o), de Coulouris et al., "um sistema distribu√≠do √© aquele no qual os componentes localizados em computadores interligados em rede se comunicam e coordenam suas a√ß√µes apenas passando mensagens". As tr√™s caracter√≠sticas que distinguem um sistema distribu√≠do s√£o: concorr√™ncia de componentes, falta de um rel√≥gio global e falhas de componentes independentes.

### b) Explique detalhadamente quatro tipos de transpar√™ncia em sistemas distribu√≠dos, fornecendo exemplos pr√°ticos de cada um usando sistemas conhecidos (WhatsApp, Gmail, Google Drive, Netflix).
- `Transpar√™ncia de acesso`: esconde as diferen√ßas na representa√ß√£o dos dados e na forma como os recursos s√£o acessados. O usu√°rio interage com o recurso da mesma forma, independentemente de sua localiza√ß√£o ou de como ele √© armazenado internamente. Exemplo: no Google Drive, o usu√°rio abre um arquivo do Google Drive da mesma maneira, tanto no seu computador, pelo aplicativo m√≥vel, ou pela web. O sistema lida com as diferen√ßas de formato e protocolo de forma transparente para que a experi√™ncia do usu√°rio seja consistente.

- `Transpar√™ncia de localiza√ß√£o`: esconde a localiza√ß√£o real dos recursos. O usu√°rio n√£o precisa saber onde um recurso est√° armazenado ou onde um servi√ßo est√° sendo executado. Exemplo: na Netflix, quando um usu√°rio assiste a um filme, a Netflix o transmite a partir de um dos milhares de servidores da sua CDN (Content Delivery Network) global. O sistema encontra automaticamente o servidor mais pr√≥ximo e com melhor desempenho para voc√™, sem que voc√™ precise saber onde ele est√°.

- `Transpar√™ncia de replica√ß√£o`: esconde o fato de que m√∫ltiplos c√≥pias de um recurso (dados ou servi√ßos) existem. A replica√ß√£o √© usada para aumentar a confiabilidade e o desempenho, mas o usu√°rio enxerga apenas um √∫nico recurso.Exemplo: no Gmail, os e-mails est√£o armazenados em v√°rios servidores para garantir que voc√™ possa acess√°-los mesmo se um dos servidores falhar. No entanto, voc√™ interage com seu e-mail como se ele estivesse em um √∫nico lugar, e o sistema garante que as mudan√ßas em uma c√≥pia sejam refletidas nas outras de forma transparente.

- `Transpar√™ncia de falha`: esconde as falhas dos componentes, permitindo que o sistema continue funcionando sem que o usu√°rio perceba a interrup√ß√£o. Exemplo: no WhatsApp, se o servidor que est√° gerenciando a conversa de um usu√°rio falhar, o sistema de mensagens o substitui por outro de forma transparente. A mensagem que voc√™ enviou pode ter um pequeno atraso, mas ela ser√° entregue e voc√™ n√£o ser√° notificado sobre o erro no servidor.

### c) Analise os principais desafios inerentes aos sistemas distribu√≠dos: heterogeneidade, falhas, concorr√™ncia e seguran√ßa. Como cada desafio impacta o projeto de arquiteturas distribu√≠das?

- `Heterogeneidade`: o desafio √© fazer com que sistemas, redes, hardware e linguagens de programa√ß√£o diferentes trabalhem juntos. A arquitetura deve incluir uma camada intermedi√°ria (middleware) que traduza a comunica√ß√£o e mascare as diferen√ßas para o programador.

- `Falhas`: falhas de rede, hardware ou software s√£o comuns. O design deve ser resiliente, com redund√¢ncia (replica√ß√£o de dados), mecanismos de detec√ß√£o de falhas e algoritmos de consenso para garantir que o sistema continue funcionando mesmo com a queda de componentes.

- `Concorr√™ncia`: m√∫ltiplos processos em diferentes m√°quinas podem tentar acessar o mesmo recurso simultaneamente. O projeto deve usar mecanismos de sincroniza√ß√£o distribu√≠da, como bloqueios e protocolos de transa√ß√£o, para evitar inconsist√™ncias nos dados.

- `Seguran√ßa`: a natureza aberta das redes torna os sistemas distribu√≠dos vulner√°veis a ataques. O design deve priorizar a seguran√ßa com criptografia, autentica√ß√£o forte e controle de acesso para proteger os dados e a comunica√ß√£o.

## Quest√£o 4 - Vantagens e Trade-offs
### a) Identifique e explique quatro vantagens fundamentais dos sistemas distribu√≠dos em rela√ß√£o aos sistemas centralizados.

Os sistemas distribu√≠dos oferecem vantagens significativas sobre os centralizados, principalmente por n√£o dependerem de um √∫nico ponto de falha. Aqui est√£o quatro das vantagens mais importantes:

1. `Confiabilidade e toler√¢ncia a falhas`: em um sistema centralizado, se a m√°quina principal falha, todo o sistema para. J√° em um sistema distribu√≠do, a falha de um componente (um n√≥ ou servidor) n√£o necessariamente paralisa o sistema inteiro. As tarefas podem ser transferidas para outros n√≥s em funcionamento, garantindo a continuidade do servi√ßo. Essa redund√¢ncia torna o sistema muito mais robusto.

2. `Escalabilidade`: sistemas centralizados t√™m um limite f√≠sico de crescimento. Para aumentar sua capacidade, √© necess√°rio fazer um upgrade de hardware (escalabilidade vertical), o que √© caro e complexo. Em sistemas distribu√≠dos, a escalabilidade √© alcan√ßada ao simplesmente adicionar mais n√≥s √† rede (escalabilidade horizontal).

3. `Performance e concorr√™ncia`: sistemas distribu√≠dos podem dividir uma tarefa grande e complexa em subtarefas menores e execut√°-las em paralelo em diferentes m√°quinas. Isso resulta em um aumento significativo da performance e da taxa de transfer√™ncia (throughput). Por exemplo, um servi√ßo de renderiza√ß√£o de v√≠deo pode usar centenas de m√°quinas para processar frames simultaneamente.

4. `Custo e distribui√ß√£o geogr√°fica`: √© mais econ√¥mico construir um sistema com m√∫ltiplas m√°quinas de baixo custo do que investir em um √∫nico supercomputador. Al√©m disso, a natureza distribu√≠da permite que os recursos sejam alocados geograficamente, posicionando servidores mais pr√≥ximos dos usu√°rios. Isso reduz a lat√™ncia de comunica√ß√£o e melhora a experi√™ncia do usu√°rio.

### b) Analise os trade-offs entre escalabilidade, confiabilidade e seguran√ßa em sistemas distribu√≠dos. Como esses trade-offs influenciam decis√µes arquiteturais? Forne√ßa um exemplo pr√°tico.

- `Escalabilidade vs. confiabilidade`: a escalabilidade busca aumentar a capacidade do sistema adicionando mais componentes (m√°quinas, servidores). No entanto, um sistema com 1000 servidores √© estatisticamente mais propenso a ter pelo menos um deles falhando em um dado momento do que um sistema com apenas 10 servidores. Aumentar a escala aumenta a probabilidade de falha de um componente. **Decis√£o arquitetural**: para manter a confiabilidade em um sistema escal√°vel, o design deve incluir mecanismos de redund√¢ncia, detec√ß√£o de falhas e recupera√ß√£o autom√°tica. O pre√ßo dessa confiabilidade √© a complexidade e a sobrecarga de gerenciar e sincronizar m√∫ltiplas r√©plicas, o que pode reduzir o desempenho.

- `Escalabilidade vs. seguran√ßa`: a seguran√ßa em um sistema centralizado √© mais f√°cil de gerenciar, pois h√° um √∫nico per√≠metro a ser protegido. Ao escalar um sistema e distribuir seus componentes por diferentes m√°quinas e redes, a superf√≠cie de ataque aumenta significativamente. A comunica√ß√£o entre os n√≥s precisa ser segura, e cada novo n√≥ pode ser um ponto de vulnerabilidade. **Decis√£o arquitetural**: garantir a seguran√ßa em um sistema distribu√≠do exige a implementa√ß√£o de controles de acesso granulares, criptografia em tr√¢nsito e em repouso, e um sistema de autentica√ß√£o e autoriza√ß√£o robusto. Essas medidas podem adicionar lat√™ncia e complexidade, impactando a performance e a simplicidade da arquitetura, que s√£o vantagens inerentes √† escalabilidade.

- `Confiabilidade vs. seguran√ßa`: a confiabilidade muitas vezes depende da replica√ß√£o de dados e servi√ßos para garantir que o sistema permane√ßa dispon√≠vel mesmo em caso de falha. No entanto, replicar dados sens√≠veis em v√°rias localiza√ß√µes aumenta o risco de um vazamento de dados, pois h√° mais c√≥pias a serem protegidas. **Decis√£o arquitetural**: para alcan√ßar a confiabilidade sem comprometer a seguran√ßa, √© necess√°rio usar criptografia forte para os dados replicados e implementar um rigoroso controle de acesso em cada r√©plica. Isso pode tornar a recupera√ß√£o de falhas mais lenta, pois o sistema precisa decifrar e validar os dados antes de torn√°-los dispon√≠veis, impactando a confiabilidade em termos de tempo de recupera√ß√£o.

**Exemplo pr√°tico: sistema banc√°rio distribu√≠do**
Um sistema banc√°rio que precisa processar milh√µes de transa√ß√µes por minuto (escalabilidade), garantir que nenhuma transa√ß√£o seja perdida (confiabilidade) e proteger as informa√ß√µes financeiras dos clientes (seguran√ßa).

- `Escalabilidade`: O sistema √© projetado com uma arquitetura de microsservi√ßos e um banco de dados distribu√≠do para lidar com o volume de transa√ß√µes. **Trade-off**: a escalabilidade para milh√µes de usu√°rios exige replicar dados e processamento em muitas m√°quinas. Isso, no entanto, torna a confiabilidade mais complexa, pois o sistema deve coordenar transa√ß√µes em r√©plicas remotas. A seguran√ßa tamb√©m √© comprometida, pois a informa√ß√£o sens√≠vel agora est√° em m√∫ltiplos locais, aumentando a superf√≠cie de ataque.
- `Confiabilidade`: O banco de dados √© replicado em tr√™s regi√µes geogr√°ficas diferentes. Se um data center inteiro falhar devido a um desastre natural, o sistema continua operando a partir das outras r√©plicas. **Trade-off**: para manter a confiabilidade, o sistema usa um algoritmo de consenso para garantir que todas as r√©plicas concordem com o estado da transa√ß√£o. Isso adiciona lat√™ncia e pode ser um gargalo de desempenho.
- `Seguran√ßa`: Cada transa√ß√£o √© criptografada e os dados do usu√°rio s√£o armazenados de forma criptografada. A comunica√ß√£o entre os microsservi√ßos tamb√©m √© criptografada. **Trade-off**: para garantir a seguran√ßa, cada transa√ß√£o pode exigir m√∫ltiplas valida√ß√µes e criptografia, o que adiciona sobrecarga computacional e aumenta a lat√™ncia, impactando o desempenho.

A decis√£o final de design n√£o √© sobre "qual √© o mais importante", mas sim sobre equilibrar esses tr√™s pilares. Para o sistema banc√°rio, a seguran√ßa e a confiabilidade s√£o inegoci√°veis. Portanto, a arquitetura sacrificar√° um pouco de desempenho (e, por consequ√™ncia, a escalabilidade m√°xima) para garantir que essas duas propriedades sejam priorit√°rias.

# üèóÔ∏è SE√á√ÉO III: ALGORITMOS DE CONSENSO
## Quest√£o 5 - Problema do Consenso
### a) Explique por que o problema do consenso √© fundamental em sistemas distribu√≠dos. Quais s√£o os principais desafios que tornam o consenso dif√≠cil em ambiente distribu√≠do?

O problema do consenso √© fundamental em sistemas distribu√≠dos porque ele garante que todos os n√≥s (computadores) em uma rede cheguem a um acordo sobre um √∫nico valor ou estado, mesmo que alguns n√≥s falhem. Sem o consenso, a consist√™ncia de um sistema seria imposs√≠vel de ser mantida. Alcan√ßar o consenso √© dif√≠cil em um ambiente distribu√≠do devido a tr√™s desafios principais:
- `Falhas`: um n√≥ pode simplesmente travar ou ficar inacess√≠vel. O sistema precisa ser capaz de continuar operando e, eventualmente, chegar a um acordo sem a participa√ß√£o do n√≥ que falhou.
- `Incerteza da rede` (Tempo ass√≠ncrono): n√£o h√° garantia sobre o tempo que uma mensagem leva para ir de um n√≥ a outro. Uma mensagem pode ser perdida, duplicada ou chegar atrasada. Isso torna imposs√≠vel saber se a falta de resposta de um n√≥ √© porque ele falhou ou apenas est√° com um atraso de comunica√ß√£o. Este √© o cerne do Teorema da Impossibilidade FLP, que mostra que, em um sistema ass√≠ncrono, √© imposs√≠vel garantir o consenso se houver a possibilidade de falha de apenas um n√≥.
- `Falhas bizantinas`: este √© o cen√°rio mais complexo, onde um n√≥ falho pode agir de forma maliciosa. Em vez de simplesmente travar, ele pode enviar informa√ß√µes conflitantes para diferentes n√≥s, tentando sabotar o sistema e impedir o consenso.

Esses desafios exigem a cria√ß√£o de algoritmos de consenso complexos, como Raft e Paxos, que s√£o projetados para funcionar de forma confi√°vel mesmo sob condi√ß√µes de falha.

### b) Defina as tr√™s propriedades fundamentais do consenso: Acordo, Validade e Termina√ß√£o. Por que todas as tr√™s s√£o necess√°rias?

As tr√™s propriedades fundamentais do consenso garantem que um algoritmo de consenso seja correto, √∫til e capaz de progredir. Elas s√£o:

1. `Acordo`: tamb√©m conhecida como consist√™ncia. Afirma que todos os processos que n√£o falham devem chegar √† mesma decis√£o. Em outras palavras, se um processo decide por um valor v, nenhum outro processo que n√£o falhe pode decidir por um valor diferente de v. Esta √© a propriedade central do consenso; se ela for violada, o sistema n√£o √© coerente. Um algoritmo que satisfa√ßa `Validade` e `Termina√ß√£o`, mas n√£o `Acordo`, poderia levar a um cen√°rio em que cada processo decide por um valor diferente, destruindo a consist√™ncia do sistema.

2. `Validade`: garante que o valor decidido deve ser um dos valores que foram propostos. Isso impede que o algoritmo de consenso "invente" um valor. Por exemplo, se os processos prop√µem os valores 5 e 8, a decis√£o final deve ser 5 ou 8, e nunca 10. A `Validade` √© essencial para que o consenso seja significativo. Um algoritmo que satisfa√ßa Acordo e Termina√ß√£o, mas n√£o `Validade`, poderia fazer com que os processos concordassem em um valor que nunca foi proposto. Por exemplo, um algoritmo que sempre decide por zero violaria esta regra, mesmo que todos concordassem.

3. `Termina√ß√£o`: afirma que todos os processos que n√£o falham devem eventualmente chegar a uma decis√£o. Em outras palavras, o algoritmo deve garantir o progresso do sistema. Sem a `Termina√ß√£o`, um algoritmo de consenso poderia rodar para sempre sem chegar a um resultado, tornando-se in√∫til na pr√°tica. Um algoritmo que satisfa√ßa `Acordo` e `Validade`, mas n√£o `Termina√ß√£o`, poderia simplesmente n√£o decidir por um valor, ficando em um loop infinito de vota√ß√£o.

Em resumo, o `Acordo` garante a coer√™ncia, a `Validade` garante a relev√¢ncia e a `Termina√ß√£o` garante o progresso. Um algoritmo de consenso s√≥ √© considerado correto se puder provar que satisfaz todas as tr√™s propriedades, mesmo em face de falhas.

### c) Descreva o algoritmo Raft explicando: os tr√™s estados poss√≠veis de um n√≥ (Leader, Follower, Candidate), o processo de elei√ß√£o de l√≠der, como funciona a replica√ß√£o de log

**Os tr√™s estados poss√≠veis de um n√≥ (Leader, Follower, Candidate)**
Cada n√≥ em um cluster Raft pode estar em um de tr√™s estados:
- `Follower`: este √© o estado inicial para todos os n√≥s. Um Follower passivamente recebe instru√ß√µes do Leader, como a replica√ß√£o de entradas de log. Ele n√£o envia mensagens para outros n√≥s e apenas responde √†s mensagens recebidas. Se ele n√£o receber uma mensagem do Leader por um certo per√≠odo de tempo (timeout de elei√ß√£o), ele se tornar√° um Candidate.
- `Candidate`: um n√≥ se torna um Candidate quando um per√≠odo de elei√ß√£o expira. O Candidate se candidata a ser o novo Leader, incrementa seu "termo" (um n√∫mero que funciona como um identificador para uma elei√ß√£o) e envia votos de requisi√ß√£o para os outros n√≥s. Ele espera por votos dos outros n√≥s.
- `Leader`: o Leader √© o √∫nico n√≥ que pode aceitar novas entradas de log e replic√°-las para os Followers. Ele se comunica constantemente com os Followers (atrav√©s de mensagens de heartbeat) para mant√™-los em sincronia e para evitar que eles se tornem Candidates.

**O processo de elei√ß√£o de l√≠der**
A elei√ß√£o de um Leader √© o mecanismo que o Raft usa para garantir que o cluster tenha um √∫nico n√≥ respons√°vel por toda a comunica√ß√£o.
- `In√≠cio da elei√ß√£o`: quando um Follower n√£o recebe um heartbeat do Leader atual por um per√≠odo de tempo aleat√≥rio, seu timeout de elei√ß√£o expira. Ele ent√£o assume que o Leader atual falhou e se torna um Candidate.
- `Vota√ß√£o`: o Candidate incrementa seu termo e envia uma mensagem de "requisi√ß√£o de voto" a todos os outros n√≥s. Cada n√≥ vota uma √∫nica vez por termo.
- `Resultado da elei√ß√£o`: o Candidate pode vencer a elei√ß√£o de tr√™s maneiras:
    - Ele recebe a maioria dos votos dos n√≥s do cluster e se torna o novo Leader.
    - Outro n√≥ se torna um Leader. Se um Candidate descobrir um novo Leader com um termo maior, ele retorna ao estado de Follower.
    - Nenhum Candidate obt√©m a maioria dos votos, o que pode acontecer em uma "elei√ß√£o dividida". Nesse caso, uma nova elei√ß√£o √© iniciada.

**Como funciona a replica√ß√£o de log**
Uma vez que um Leader √© eleito, ele se torna respons√°vel por replicar o log de transa√ß√µes. O log √© a √∫nica fonte da verdade no Raft.
- `Nova entrada`: o Leader recebe uma nova entrada de log (por exemplo, uma transa√ß√£o de escrita). Ele anexa essa entrada ao seu pr√≥prio log.
- `Envio para followers`: o Leader envia uma mensagem de AppendEntries para todos os seus Followers, que inclui a nova entrada de log.
- `Confirma√ß√£o e compromisso`: quando um Follower recebe a entrada de log, ele a anexa ao seu pr√≥prio log e envia uma confirma√ß√£o de sucesso para o Leader. O Leader aguarda as confirma√ß√µes da maioria dos Followers. Quando a maioria dos n√≥s confirma que a entrada foi replicada, o Leader a marca como comprometida (committed) em seu pr√≥prio log e executa a transa√ß√£o. Em seguida, o Leader notifica os Followers que a entrada foi comprometida. Os Followers tamb√©m a marcam como comprometida e a executam.

Este processo garante que todos os n√≥s do cluster tenham uma c√≥pia id√™ntica e consistente do log, e que as transa√ß√µes s√≥ sejam consideradas permanentes ap√≥s a confirma√ß√£o da maioria. Se o Leader falhar durante a replica√ß√£o, o processo de elei√ß√£o √© acionado novamente, e o novo Leader restaurar√° a consist√™ncia do log.

## Quest√£o 6 - Compara√ß√£o de Algoritmos
### Compare os algoritmos Raft, Paxos e PBFT considerando: complexidade de compreens√£o e implementa√ß√£o, toler√¢ncia a falhas, performance e lat√™ncia, e casos de uso adequados. Quando voc√™ recomendaria cada algoritmo?
| Caracter√≠stica | Raft | Paxos | PBFT (Practical Byzantine Fault Tolerance) |
|----------------|------|-------|--------------------------------------------|
| Complexidade de Compreens√£o e Implementa√ß√£o | Baixa. Projetado para ser compreens√≠vel e f√°cil de implementar. √â o mais popular para iniciantes e para a maioria dos casos de uso. | Muito alta. Conhecido por ser extremamente dif√≠cil de entender e implementar corretamente. | M√©dia. Mais complexo que o Raft devido √† necessidade de lidar com falhas bizantinas, mas mais pr√°tico que o Paxos. |
| Toler√¢ncia a Falhas                | Toler√¢ncia a falhas de crash. Um n√≥ pode falhar ao travar ou se desconectar. Requer que a maioria (mais de 50%) dos n√≥s esteja funcionando. | Toler√¢ncia a falhas de crash. Tem a mesma toler√¢ncia a falhas do Raft e tamb√©m exige que a maioria dos n√≥s esteja online. | Toler√¢ncia a falhas bizantinas. Um n√≥ pode agir de forma maliciosa (enviar mensagens falsas). Tolera falhas de at√© ‚åä(N‚àí1)/3‚åã n√≥s. |
| Performance e Lat√™ncia             | Boa performance. Em opera√ß√£o normal, apenas o l√≠der processa as solicita√ß√µes, o que √© r√°pido. A lat√™ncia aumenta durante uma elei√ß√£o de l√≠der. | Performance vari√°vel. O algoritmo b√°sico tem alta lat√™ncia. Vers√µes otimizadas como o Paxos Multi-Decree melhoram a performance ao pre√ßo de maior complexidade. | M√©dia a baixa performance. O overhead de criptografia para assinar mensagens e os m√∫ltiplos est√°gios de comunica√ß√£o levam a uma performance inferior em compara√ß√£o com o Raft. |
| Casos de Uso Adequados             | Ambientes com confian√ßa entre n√≥s. √â a escolha padr√£o para sistemas distribu√≠dos em que os n√≥s pertencem √† mesma organiza√ß√£o e a falha se deve a causas t√©cnicas (por exemplo, um servidor que trava). | Casos hist√≥ricos ou acad√™micos. √â pouco usado em novas implementa√ß√µes devido √† sua complexidade. Muitos sistemas que afirmam usar Paxos, na verdade, usam variantes simplificadas. | Ambientes com n√≥s n√£o confi√°veis. Ideal para sistemas em que os participantes n√£o confiam uns nos outros, como redes de blockchain privadas ou cons√≥rcios entre diferentes empresas. |

- `Raft`: recomenda-se o Raft para a grande maioria das aplica√ß√µes de sistema distribu√≠do. Sua simplicidade de implementa√ß√£o e robustez para lidar com falhas de crash o tornam a melhor op√ß√£o. √â perfeito para replicar logs, gerenciar servi√ßos de configura√ß√£o (como o etcd ou Consul) e manter estados consistentes em data centers.
- `Paxos`: atualmente, a n√£o ser que haja uma necessidade muito espec√≠fica, n√£o √© recomendado o uso do Paxos. O Raft cobre os mesmos casos de uso com um algoritmo muito mais f√°cil de entender e manter. O Paxos √© mais relevante para o estudo acad√™mico ou para sistemas legados que j√° o utilizam.
- `PBFT`: recomenda-se o PBFT para cen√°rios onde a seguran√ßa contra ataques maliciosos √© a principal prioridade. √â a escolha adequada para sistemas onde os participantes s√£o an√¥nimos ou pertencem a diferentes organiza√ß√µes, como em uma rede de blockchain privada ou um sistema de vota√ß√£o.

# üèõÔ∏è SE√á√ÉO IV: MODELOS E ARQUITETURAS
## Quest√£o 7 - Arquiteturas Fundamentais
### a) Compare detalhadamente as arquiteturas Cliente-Servidor e Peer-to-Peer (P2P): caracter√≠sticas principais de cada uma, vantagens e desvantagens exemplos pr√°ticos de sistemas que utilizam cada arquitetura

| Caracter√≠stica       | Cliente-Servidor | Peer-to-Peer (P2P) |
|---------------------|-----------------|------------------|
| Caracter√≠sticas principais | Modelo Centralizado. Clientes solicitam servi√ßos a um servidor central, que processa e responde. A comunica√ß√£o √© sempre iniciada pelo cliente. O servidor √© um ponto fixo e crucial. | Modelo Descentralizado. Todos os n√≥s (peers) s√£o iguais, atuando tanto como clientes quanto como servidores. A comunica√ß√£o pode ocorrer diretamente entre os peers. |
| Vantagens            | - Controle Centralizado: Facilita a seguran√ßa, o gerenciamento de dados e a auditoria.<br>- Estabilidade: Se o servidor for robusto, o sistema √© previs√≠vel e est√°vel.<br>- Simplicidade de Busca: Encontrar um recurso √© simples, pois ele est√° em um local conhecido (o servidor). | - Escalabilidade: F√°cil de escalar; basta adicionar mais peers para aumentar a capacidade.<br>- Toler√¢ncia a Falhas: A falha de um n√≥ n√£o afeta o sistema como um todo.<br>- Custo Baixo: N√£o exige um servidor central de alto custo. |
| Desvantagens         | - Ponto √önico de Falha: Se o servidor cair, o sistema inteiro fica indispon√≠vel.<br>- Gargalo de Performance: O servidor pode ficar sobrecarregado com muitas requisi√ß√µes simult√¢neas.<br>- Custo de Infraestrutura: Exige a manuten√ß√£o de um ou mais servidores dedicados. | - Seguran√ßa: Dif√≠cil de gerenciar e auditar, pois os dados est√£o espalhados por v√°rios n√≥s.<br>- Gerenciamento: Dif√≠cil de controlar e atualizar o sistema, j√° que n√£o h√° um ponto central.<br>- Busca de Recursos: A busca por um recurso pode ser mais lenta e complexa. |
| Exemplos Pr√°ticos    | Navega√ß√£o na Web (HTTP): Seu navegador (cliente) se conecta ao servidor do Google para obter uma p√°gina.<br>E-mail (SMTP/IMAP): Seu cliente de e-mail se conecta ao servidor do Gmail para enviar ou receber mensagens. | Compartilhamento de Arquivos: O BitTorrent permite que voc√™ baixe um arquivo de v√°rios usu√°rios ao mesmo tempo.<br>Criptomoedas (Bitcoin): Cada n√≥ na rede P2P verifica e valida as transa√ß√µes diretamente com outros n√≥s. |


### b) Explique o conceito de arquiteturas h√≠bridas e como sistemas como a Netflix combinam elementos centralizados e distribu√≠dos (CDN, microservi√ßos).

Uma **arquitetura h√≠brida** √© um modelo de sistema que combina as vantagens dos sistemas centralizados e distribu√≠dos. Em vez de operar inteiramente a partir de um √∫nico servidor ou ser completamente descentralizado, ela utiliza uma abordagem mista, onde cada componente √© otimizado para a sua fun√ß√£o.

A Netflix n√£o depende de um servidor central para gerenciar e entregar todo o seu conte√∫do, mas tamb√©m n√£o √© um sistema P2P (Peer-to-Peer). Em vez disso, ela combina elementos de ambas as arquiteturas para garantir a melhor experi√™ncia poss√≠vel.

A **parte centralizada** da Netflix √© respons√°vel por gerenciar dados cr√≠ticos que exigem alta consist√™ncia e controle. Essa l√≥gica √© complexa e deve ser mantida de forma segura e consistente em um local central para evitar erros. J√° a maior parte da opera√ß√£o da Netflix √© **distribu√≠da** e constru√≠da em uma arquitetura de microsservi√ßos. Em vez de ter um √∫nico e grande programa (monolito), a l√≥gica do aplicativo √© dividida em centenas de servi√ßos menores e independentes. Al√©m disso, √© utilizado CDN para armazenar o conte√∫do em milhares de servidores espalhados pelo mundo, localizados estrategicamente em pontos de troca de internet ou dentro das redes dos pr√≥prios provedores.

Em resumo, a Netflix utiliza um modelo h√≠brido para capitalizar as vantagens de cada arquitetura. Ela usa o controle e a consist√™ncia dos sistemas centralizados para os dados cr√≠ticos de neg√≥cio e a escalabilidade e a baixa lat√™ncia dos sistemas distribu√≠dos para a entrega de conte√∫do.

### c) Discuta as varia√ß√µes da arquitetura cliente-servidor: thin client, thick client e multi-tier. Quando cada varia√ß√£o √© mais adequada?
- `Thin Client`: na arquitetura thin client, a maior parte do processamento da aplica√ß√£o ocorre no servidor. O cliente, que pode ser um dispositivo de baixo poder de processamento, √© respons√°vel apenas por exibir a interface gr√°fica e enviar as entradas do usu√°rio. Essa abordagem √© mais adequada para ambientes que exigem controle e seguran√ßa centralizados, como caixas de banco ou redes corporativas, onde o acesso aos dados √© restrito ao servidor.
- `Thick Client`: a maior parte da l√≥gica e do processamento reside no lado do cliente. O cliente √© um software robusto, que usa o servidor principalmente para armazenamento de dados e sincroniza√ß√£o. Essa arquitetura √© ideal para aplica√ß√µes que precisam de alto desempenho e podem funcionar offline, como softwares de edi√ß√£o de v√≠deo, jogos de computador ou aplicativos de desktop complexos.
- `Multi-Tier` (M√∫ltiplas Camadas): a arquitetura multi-tier divide o sistema em m√∫ltiplas camadas l√≥gicas, como a camada de apresenta√ß√£o (o cliente), a camada de l√≥gica de neg√≥cio e a camada de dados. Cada camada pode ser executada em servidores separados, permitindo que a aplica√ß√£o seja mais modular, flex√≠vel e escal√°vel. Essa √© a arquitetura padr√£o para a maioria dos grandes sistemas distribu√≠dos, como servi√ßos de e-commerce ou plataformas de streaming, pois ela permite que cada camada seja escalada de forma independente para atender √† demanda.

## Quest√£o 8 - Modelos de Intera√ß√£o
### a) Explique as diferen√ßas entre comunica√ß√£o s√≠ncrona e ass√≠ncrona em sistemas distribu√≠dos. Quais s√£o as implica√ß√µes de cada modelo para performance e confiabilidade?

A comunica√ß√£o **s√≠ncrona** √© um modelo onde o emissor envia uma mensagem e aguarda a resposta antes de continuar qualquer outra tarefa. Pense nela como uma chamada telef√¥nica: voc√™ fala e espera a outra pessoa responder para poder continuar.
- Implica√ß√µes: a principal vantagem √© a simplicidade de implementa√ß√£o. No entanto, ela introduz alta lat√™ncia, pois o processo fica bloqueado. Se o receptor falhar, o emissor tamb√©m pode travar, comprometendo a confiabilidade do sistema.

A comunica√ß√£o **ass√≠ncrona** √© um modelo onde o emissor envia uma mensagem e continua seu trabalho imediatamente, sem esperar pela resposta. A resposta √© processada posteriormente, muitas vezes por meio de um mecanismo de notifica√ß√£o ou evento.
- Implica√ß√µes: a performance √© muito melhor! Pois os processos n√£o ficam bloqueados, permitindo que a aplica√ß√£o fa√ßa v√°rias coisas ao mesmo tempo. Isso aumenta a toler√¢ncia a falhas e a confiabilidade, j√° que a falha de um servi√ßo n√£o impede o progresso do emissor. A desvantagem √© a complexidade de implementa√ß√£o, j√° que o c√≥digo precisa gerenciar retornos e eventos.

### b) Analise diferentes tipos de falhas em sistemas distribu√≠dos (crash, omiss√£o, bizantina) e como cada tipo impacta o design do sistema.
- `Falha de crash`: ocorre quando um n√≥ simplesmente para de funcionar de forma abrupta. √â a falha mais simples de lidar. O impacto no design √© a necessidade de redund√¢ncia e mecanismos de failover. O sistema deve ser projetado para que outro n√≥ possa assumir a tarefa do n√≥ que falhou, garantindo a continuidade do servi√ßo.

- `Falha de omiss√£o`: acontece quando um n√≥ falha em enviar ou receber mensagens. O n√≥ em si pode estar funcionando, mas a comunica√ß√£o √© interrompida. O impacto no design √© a implementa√ß√£o de timeouts e retransmiss√µes. O sistema precisa ser capaz de detectar a aus√™ncia de resposta e reenviar a mensagem, ou considerar o n√≥ como falho temporariamente.

- `Falha Bizantina`: √© a mais complexa e grave, pois um n√≥ age de forma maliciosa. Ele pode enviar dados falsos ou mensagens contradit√≥rias para diferentes n√≥s, tentando sabotar o sistema. O impacto no design √© a necessidade de algoritmos de consenso bizantino (como o PBFT) que exigem m√∫ltiplos est√°gios de comunica√ß√£o e valida√ß√µes criptogr√°ficas para garantir que os n√≥s honestos cheguem a um acordo mesmo com a presen√ßa de n√≥s traidores.

# üî¨ SE√á√ÉO V: ESTUDO DE CASO E APLICA√á√ÉO
## Quest√£o 9 - An√°lise Cr√≠tica da Netflix
### a) Identifique cinco tipos de transpar√™ncia que a Netflix implementa para seus usu√°rios. Explique como cada transpar√™ncia √© alcan√ßada na pr√°tica.
Os sistemas distribu√≠dos criam a ilus√£o de um sistema √∫nico e coeso. A Netflix utiliza v√°rios tipos de transpar√™ncia para fazer isso, e aqui est√£o cinco exemplos:
- `Transpar√™ncia de acesso`: o usu√°rio acessa o conte√∫do com uma URL simples, sem se preocupar com o formato ou protocolo dos dados, que √© tratado internamente pela Netflix.
- `Transpar√™ncia de localiza√ß√£o`: o usu√°rio n√£o precisa saber onde o filme est√° armazenado. A Netflix utiliza sua CDN global para automaticamente conectar o usu√°rio ao servidor mais pr√≥ximo, reduzindo a lat√™ncia.
- `Transpar√™ncia de replica√ß√£o`: o usu√°rio n√£o tem conhecimento de que o mesmo filme est√° armazenado em v√°rias c√≥pias ao redor do mundo. A Netflix faz isso para garantir que o conte√∫do esteja sempre dispon√≠vel, mesmo com alta demanda.
- `Transpar√™ncia de falha`: se um dos servidores de streaming cair, o sistema automaticamente e de forma transparente redireciona a conex√£o do usu√°rio para outro servidor em funcionamento. Isso evita interrup√ß√µes na reprodu√ß√£o.
- `Transpar√™ncia de concorr√™ncia`: v√°rios usu√°rios podem assistir ao mesmo filme simultaneamente sem interferir uns nos outros. O sistema lida com o acesso de forma coordenada e sem que o usu√°rio perceba.

### b) Analise a arquitetura da Netflix como um sistema h√≠brido: quais componentes s√£o centralizados Quais componentes s√£o distribu√≠dos? Como a CDN (Content Delivery Network) contribui para performance e escalabilidade?
- **Componentes centralizados**: a parte centralizada da Netflix √© respons√°vel por gerenciar dados cr√≠ticos que exigem alta consist√™ncia e controle. Esta camada inclui a gest√£o de contas de usu√°rio, o sistema de autentica√ß√£o, os pagamentos, o sistema de recomenda√ß√£o (que personaliza o cat√°logo para cada usu√°rio) e o gerenciamento do cat√°logo de filmes e s√©ries. Essa l√≥gica √© complexa e deve ser mantida de forma segura e consistente em um local central para evitar erros.

- **Componentes distribu√≠dos**: a maior parte da opera√ß√£o da Netflix √© distribu√≠da e constru√≠da em uma arquitetura de microsservi√ßos. Em vez de ter um √∫nico e grande programa (monolito), a l√≥gica do aplicativo √© dividida em centenas de servi√ßos menores e independentes. Um microsservi√ßo cuida do login, outro do hist√≥rico de visualiza√ß√µes, outro do carregamento da interface do usu√°rio, e assim por diante. Essa abordagem permite que a Netflix escale cada servi√ßo de forma independente para atender √† demanda, garantindo alta disponibilidade.

- **Papel da CDN** (Content Delivery Network): a pe√ßa mais importante do modelo distribu√≠do da Netflix √© a sua CDN global, chamada Open Connect. Em vez de entregar o streaming de um servidor central, o conte√∫do √© armazenado em milhares de servidores espalhados pelo mundo, localizados estrategicamente em pontos de troca de internet ou dentro das redes dos pr√≥prios provedores.
        - Performance: quando o usu√°rio clica "play", o v√≠deo √© transmitido do servidor mais pr√≥ximo. Isso reduz a lat√™ncia e o tempo de carregamento.
        - Escalabilidade: a carga de streaming n√£o sobrecarrega os servidores centrais da Netflix. Em vez disso, a demanda √© distribu√≠da para a CDN, que pode atender a milh√µes de usu√°rios simultaneamente.

### c) Como a Netflix lida com os desafios de heterogeneidade (diferentes dispositivos, redes, regi√µes geogr√°ficas) e falhas?
A Netflix usa uma arquitetura de microsservi√ßos para que cada componente (como a interface de usu√°rio ou a l√≥gica de recomenda√ß√£o) possa ser adaptado para diferentes dispositivos, de TVs a celulares. Al√©m disso, ela utiliza streaming de v√≠deo adapt√°vel, ajustando automaticamente a qualidade do v√≠deo de acordo com a velocidade da rede do usu√°rio, garantindo uma experi√™ncia fluida em qualquer conex√£o.

Para as falhas, a estrat√©gia da Netflix √© a redund√¢ncia e a resili√™ncia. Dados e servi√ßos s√£o replicados em m√∫ltiplos servidores e em diferentes data centers. Se um servidor falha, o tr√°fego √© automaticamente redirecionado para outro que esteja funcionando. Essa abordagem garante que o sistema permane√ßa dispon√≠vel mesmo em caso de falha de um ou mais componentes.

## Quest√£o 10 - Mapeamento Conceitual
Demonstre como os conceitos de Sistemas Operacionais se estendem para Sistemas Distribu√≠dos. Preencha cada linha com o equivalente distribu√≠do e uma breve explica√ß√£o

1. `Processo`: o equivalente √© um Processo Distribu√≠do. Um processo em um sistema distribu√≠do √© uma unidade de execu√ß√£o que opera em uma m√°quina separada, comunicando-se com outros processos atrav√©s de uma rede.
2. `IPC`: o equivalente √© um RPC (Remote Procedure Call). O IPC, que em um S.O. √© local, se estende para a comunica√ß√£o entre m√°quinas. Mecanismos como RPC fazem com que uma chamada de fun√ß√£o remota pare√ßa uma chamada local.
3. `Sincroniza√ß√£o`: o equivalente s√£o algoritmos de consenso. Como n√£o existe um √∫nico rel√≥gio global, a sincroniza√ß√£o se baseia em rel√≥gios l√≥gicos ou algoritmos de consenso para estabelecer uma ordem consistente de eventos entre diferentes n√≥s.
4. `Gerenciamento de mem√≥ria`: o equivalente √© a Mem√≥ria Compartilhada Distribu√≠da (DSM). A DSM cria a ilus√£o de um √∫nico espa√ßo de mem√≥ria compartilhado por v√°rias m√°quinas. Os dados s√£o replicados e gerenciados para parecerem locais para os processos.
5. `Sistema de arquivos`: o equivalente √© um Sistema de Arquivos Distribu√≠do (DFS). Um DFS permite que um usu√°rio acesse arquivos armazenados em um servidor remoto como se estivessem na sua m√°quina local, gerenciando de forma transparente o acesso e a consist√™ncia dos dados.

# üìö SE√á√ÉO VI: QUEST√ïES DISSERTATIVAS AVAN√áADAS
## Quest√£o 11 - An√°lise Comparativa
Uma empresa precisa escolher entre uma arquitetura cliente-servidor tradicional e uma arquitetura P2P para um novo sistema de compartilhamento de arquivos corporativo. Analise este cen√°rio considerando:
- Requisitos de seguran√ßa corporativa
- Controle administrativo
- Escalabilidade para 10.000 usu√°rios
- Toler√¢ncia a falhas
- Custos de infraestrutura
Justifique sua recomenda√ß√£o com base nos conceitos estudados.

Segue uma an√°lise de cada uma das arquiteturas.

**Arquitetura cliente-servidor**
- `Requisitos de seguran√ßa e controle`: esta arquitetura √© ideal para ambientes corporativos. A seguran√ßa e o controle administrativo podem ser gerenciados de forma centralizada no servidor. √â f√°cil implementar pol√≠ticas de acesso rigorosas, autentica√ß√£o de usu√°rios, criptografia de dados em tr√¢nsito e em repouso, e realizar auditorias regulares.
- `Escalabilidade e toler√¢ncia a falhas`: a escalabilidade pode ser um desafio, pois o servidor pode se tornar um gargalo de desempenho. No entanto, √© um problema conhecido e solucion√°vel com estrat√©gias como a escalabilidade horizontal (adicionando mais servidores) e o uso de balanceadores de carga. A toler√¢ncia a falhas √© um risco, pois a falha do servidor central derruba o sistema. Isso pode ser mitigado com redund√¢ncia e sistemas de failover, embora com custos adicionais.
- `Custos de infraestrutura`: exige um investimento inicial maior em servidores dedicados e infraestrutura de rede robusta.

**Arquitetura Peer-to-Peer (P2P)**
- `Requisitos de seguran√ßa e controle`: a seguran√ßa √© o principal ponto fraco do P2P em um ambiente corporativo. A descentraliza√ß√£o da rede torna a seguran√ßa e o controle administrativo praticamente imposs√≠veis de gerenciar. Os dados corporativos estariam espalhados em milhares de dispositivos, muitos fora do controle da TI, criando um risco enorme de vazamento de dados e vulnerabilidade a malwares.
- `Escalabilidade e toler√¢ncia a falhas`: esta √© a grande vantagem do P2P. A rede escala de forma natural e a toler√¢ncia a falhas √© inerente, j√° que a falha de um n√≥ n√£o afeta a disponibilidade do sistema. A capacidade da rede aumenta √† medida que mais usu√°rios se conectam.
- `Custos de infraestrutura`: o custo inicial √© baixo, pois a arquitetura utiliza a infraestrutura j√° existente dos usu√°rios, como seus pr√≥prios computadores e redes.

Com base na an√°lise do cen√°rio e nos conceitos de arquitetura de sistemas distribu√≠dos, a arquitetura cliente-servidor tradicional √© a escolha mais adequada para um sistema de compartilhamento de arquivos corporativo. Embora o modelo P2P ofere√ßa vantagens em escalabilidade e custo, ele falha em atender √†s exig√™ncias mais cr√≠ticas para uma empresa: seguran√ßa e controle administrativo. Em um sistema corporativo, a integridade e a confidencialidade dos dados s√£o inegoci√°veis. O modelo P2P n√£o oferece mecanismos confi√°veis para garantir que os dados estejam seguros. As quest√µes de escalabilidade e toler√¢ncia a falhas do modelo cliente-servidor podem ser resolvidas com solu√ß√µes t√©cnicas e investimento, mas a falta de controle do P2P √© uma falha fundamental para este caso.

## Quest√£o 12 - Projeto Conceitual
Desafio: Projete conceitualmente um sistema distribu√≠do para vota√ß√£o eletr√¥nica que deve garantir:
- Transpar√™ncia de acesso (votar de qualquer local)
- Transpar√™ncia de falha (sistema sempre dispon√≠vel)
- Seguran√ßa e auditabilidade
- Escalabilidade nacional

**Arquitetura escolhida e justificativa**
Para um sistema de vota√ß√£o eletr√¥nica, a arquitetura ideal seria **h√≠brida**. A parte centralizada seria respons√°vel pelo registro e autentica√ß√£o dos eleitores. Uma autoridade central garante que cada cidad√£o tenha uma √∫nica identidade e possa votar apenas uma vez. Esta camada tamb√©m cuidaria da contagem final de votos.

A parte distribu√≠da, por sua vez, seria uma rede de n√≥s (peers) que receberiam, validariam e replicariam os votos. Essa abordagem combina a seguran√ßa e o controle da arquitetura centralizada com a escalabilidade, a resili√™ncia e a transpar√™ncia de uma rede descentralizada.

**Algoritmo de consenso adequado**
Quanto ao algoritmo de consenso, o adequado para este sistema √© o **PBFT** (Practical Byzantine Fault Tolerance). A principal raz√£o para essa escolha √© que o PBFT √© projetado para lidar com falhas bizantinas, onde um n√≥ pode agir de forma maliciosa, tentando corromper o sistema. Em um sistema de vota√ß√£o, n√£o podemos assumir que todos os n√≥s s√£o confi√°veis. O PBFT garante que o sistema chegue a um consenso e mantenha a integridade do log de votos.

**Principais desafios e como ser√£o tratados**
- `Seguran√ßa e integridade do voto`: cada voto seria criptografado com chaves p√∫blicas e privadas e tratado como uma transa√ß√£o imut√°vel. A auditabilidade √© garantida por um log de transa√ß√µes distribu√≠do e p√∫blico, onde cada voto √© registrado de forma an√¥nima e transparente.

- `Escalabilidade nacional`: a rede distribu√≠da de n√≥s lidaria com o alto volume de requisi√ß√µes. Para otimizar a performance, o sistema poderia usar sharding, dividindo a rede em grupos (ou "shards") para processar votos por regi√£o geogr√°fica, aliviando a carga sobre a rede.

- `Transpar√™ncia de falha`: a replica√ß√£o de dados em m√∫ltiplos n√≥s com o algoritmo PBFT garante que, se um ou mais servidores falharem, a rede continue funcionando e o log de votos n√£o seja perdido. O sistema automaticamente redireciona o tr√°fego para os n√≥s em funcionamento.

**Tipos de transpar√™ncia implementados**
- `Transpar√™ncia de acesso`: os eleitores podem votar de qualquer lugar, de forma simples, sem se preocupar com os detalhes t√©cnicos de acesso. O sistema lida com a conex√£o de forma transparente.

- `Transpar√™ncia de falha`: o sistema se mant√©m dispon√≠vel mesmo com a falha de n√≥s. A falha de um componente n√£o √© percept√≠vel para o eleitor.

- `Transpar√™ncia de concorr√™ncia`: v√°rios eleitores podem votar ao mesmo tempo. O sistema gerencia as transa√ß√µes de forma transparente, garantindo que n√£o haja conflitos.

- `Transpar√™ncia de localiza√ß√£o`: o eleitor n√£o precisa saber onde o voto √© processado ou armazenado, pois o sistema se conecta automaticamente ao servidor mais pr√≥ximo e dispon√≠vel para processar a transa√ß√£o.